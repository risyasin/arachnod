<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <title>JSDoc: Home</title>

    <script src="scripts/prettify/prettify.js"> </script>
    <script src="scripts/prettify/lang-css.js"> </script>
    <!--[if lt IE 9]>
      <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    <link type="text/css" rel="stylesheet" href="styles/prettify-tomorrow.css">
    <link type="text/css" rel="stylesheet" href="styles/jsdoc-default.css">
</head>

<body>

<div id="main">

    <h1 class="page-title">Home</h1>

    



    


    <h3> </h3>










    




    <section>
        <article><h3>Arachnod</h3><h4>High performance crawler for Nodejs</h4><p>Powerful &amp; Easy to use web crawler for Nodejs.  <a href="http://arachnod.evrima.net">Arachnod</a> has been designed for heavy and long running tasks, 
for performance &amp; efective resource usage. For it's goals Arachnod uses <a href="http://www.redis.io">Redis</a>'s power as a backend. 
Covering all heavy &amp; time consuming tasks such as controlling urls &amp; their tasks to store &amp; distribute information among the Arachnod's child tasks 
(Spiderlings). Arachnod also avoids to use any server-side DOM requiring technics 
such as <a href="http://www.jquery.com">jQuery</a> with <a href="https://github.com/tmpvar/jsdom">JSdom</a> to use resources properly. 
Frankly, I have tested JSdom for along time with no luck, always memory leaks &amp; high memory usage. 
Libxml based XPath solutions were not actually real, Instead, Arachnod uses <a href="http://cheeriojs.github.io/cheerio/">Cheerio</a> for accessing DOM elements. 
Also uses <a href="https://github.com/visionmedia/superagent">SuperAgent</a> as HTTP Client. </p>
<h3>How to install</h3><p><code>$ npm install arachnod</code></p>
<p>Or via Git
<code>$ git clone git@github.com:risyasin/arachnod.git</code></p>
<p>Then, install required Nodejs modules with npm 
<code>$ npm install</code></p>
<p><strong>Please</strong> make sure you have a running <a href="https://redis.io">redis-server</a> </p>
<h3>How to use</h3><pre class="prettyprint source lang-js"><code>var bot = require('arachnod');

bot.on('hit', function (doc, $) {

    // Do whatever you want to do parsed html content.

    var desc = $('article.entry-content').text();

    console.log(doc.path, desc);

    // if you don't need to follow all links.
    bot.pause();


});


bot.crawl({
    'redis': '127.0.0.1',
    'parallel': 4,
    'start': 'https://github.com/risyasin/arachnod',
    'resume': false
});


bot.on('error', function (err, task) {
    log('Bot error:', err, err.stack, task);
});


bot.on('end', function (err, status) {
    log('Bot finished:', err, status);
});</code></pre><h3>Documentation</h3><h5>Parameters</h5><table>
<thead>
<tr>
<th>Parameter Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>start</strong></td>
<td>Start url for crawling (Mandatory) </td>
</tr>
<tr>
<td><strong>parallel</strong></td>
<td>Number of child processes that will handle network tasks (Default: 8) Do not this more than 20. </td>
</tr>
<tr>
<td><strong>redis</strong></td>
<td>Host name or IP address that Redis runs on (Default: 127.0.0.1)</td>
</tr>
<tr>
<td><strong>redisPort</strong></td>
<td>Port number for Redis (Default: 6379)</td>
</tr>
<tr>
<td><strong>verbose</strong></td>
<td>Arachnod will tell you more, <strong>1</strong> (silence) - <strong>10</strong> (everything). Default: 1.</td>
</tr>
<tr>
<td><strong>resume</strong></td>
<td>Resume support, Simply, does not resets queues if there is any. (Default: false) </td>
</tr>
<tr>
<td><strong>ignorePaths</strong></td>
<td>Ignores paths starts with. Must be multiple in array syntax such as <code>['/blog','/gallery']</code> </td>
</tr>
<tr>
<td><strong>ignoreParams</strong></td>
<td>Ignores query string parameters, Must be in array syntax. such as <code>['color','type']</code>  </td>
</tr>
<tr>
<td><strong>sameDomain</strong></td>
<td>Stays in the same hostname. (will be implemented at v1)</td>
</tr>
<tr>
<td><strong>useCookies</strong></td>
<td>Using cookies (will be implemented at v0.4)</td>
</tr>
<tr>
<td><strong>obeyRobotsTxt</strong></td>
<td>As it's name says. Honors the robots.txt (will be implemented at v0.5) </td>
</tr>
</tbody>
</table>
<h5>Events</h5><table>
<thead>
<tr>
<th>Event Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>hit</strong></td>
<td>Emits when a url has been downloaded &amp; processed, sends two parameters in order <em>doc</em> Parsed url info, <strong>$</strong> as Cheerio object. </td>
</tr>
<tr>
<td><strong>error</strong></td>
<td>Emits when an error occurs at any level including child processes. Single parameter Error or Exception.  </td>
</tr>
<tr>
<td><strong>end</strong></td>
<td>Emits when reached at the end of tasks queue. Return statistics.  </td>
</tr>
<tr>
<td><strong>stats</strong></td>
<td>Emits bot stats whenever a child changes it's states (such as downloading or querying queues). Use wisely.  </td>
</tr>
</tbody>
</table>
<h5>Methods</h5><table>
<thead>
<tr>
<th>Method Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>crawl(Parameters)</strong></td>
<td>Starts a new crawling session with parameters</td>
</tr>
<tr>
<td><strong>pause()</strong></td>
<td>Stops bot but does not delete any task queue.</td>
</tr>
<tr>
<td><strong>resume()</strong></td>
<td>Starts back a paused session. Useful to control resource usage in low spec systems (single core etc.). </td>
</tr>
<tr>
<td><strong>queue(url)</strong></td>
<td>Adds given url to task queue. </td>
</tr>
<tr>
<td><strong>getStats()</strong></td>
<td>Returns various statistics such as downloaded, checked, finished url counts, memory size etc. </td>
</tr>
</tbody>
</table>
<h5>What's Next</h5><ul>
<li>Regex support for ignore parameters</li>
<li>Cookie support</li>
<li>Robots.txt &amp; rel=nofollow support</li>
<li>Actions for content-type or any given response headers </li>
<li>Custom headers</li>
<li>Custom POST/PUT method queues</li>
<li>Free-Ride mode (will be fun)</li>
<li>Stats for each download/hit event</li>
<li>Plugin support</li>
</ul>
<h4>Support</h4><p>If you love to use Arachnod. Help me to improve it. 
Feel free to make pull request for anything useful. </p>
<h4>License</h4><p>GNU - Version 2</p></article>
    </section>






</div>

<nav>
    <h2><a href="index.html">Home</a></h2><h3>Namespaces</h3><ul><li><a href="Arachnod.html">Arachnod</a></li></ul><h3>Global</h3><ul><li><a href="global.html#finish">finish</a></li><li><a href="global.html#getTask">getTask</a></li><li><a href="global.html#getUrl">getUrl</a></li><li><a href="global.html#processResponse">processResponse</a></li><li><a href="global.html#run">run</a></li><li><a href="global.html#taskRetry">taskRetry</a></li></ul>
</nav>

<br class="clear">

<footer>
    Documentation generated by <a href="https://github.com/jsdoc3/jsdoc">JSDoc 3.4.0</a> on Sat Jan 30 2016 15:14:09 GMT+0200 (EET)
</footer>

<script> prettyPrint(); </script>
<script src="scripts/linenumber.js"> </script>
</body>
</html>